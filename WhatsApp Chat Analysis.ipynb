{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing libraries and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "#Library for sentiment analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#Libraries for generating the word cloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading txt file as text\n",
    "file_path = r'<Insert txt file path here>' \n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    file_contents = file.read()\n",
    "\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation of file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End goal is to have a dataframe with the columns date, time, participant and message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Initial dataframe cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting each new line and converting to list\n",
    "file_contents = file_contents.split('\\n').copy()\n",
    "\n",
    "#Converting to dataframe\n",
    "df = pd.DataFrame(file_contents)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming column\n",
    "df.rename(columns={0:'Text'},inplace=True)\n",
    "\n",
    "#Removing blank rows\n",
    "df = df[df['Text']!=''].copy()\n",
    "\n",
    "#Removing standard WhatsApp messages\n",
    "df = df[~(df['Text'].str.contains(' was added') | df['Text'].str.contains('changed the group name') | df['Text'].str.contains('calls are end-to-end encrypted') | df['Text'].str.contains(' omitted'))].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Parsing text into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to parse text\n",
    "def extract_timestamp(column,text):\n",
    "\n",
    "    #Defining patterns\n",
    "    patterns = {'Timestamp':'\\[([^\\]]+)\\] ',\n",
    "                'Participant':'\\]\\s*(.*?):',\n",
    "                'Message':'\\d{2}:\\d{2}:\\d{2}\\] .*?:\\s*(.*)$'}\n",
    "\n",
    "    match = re.search(patterns.get(column), text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    elif column == 'Message':\n",
    "        return text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#Applying function to create relevant columns\n",
    "df['Timestamp'] = df['Text'].apply(lambda x: extract_timestamp('Timestamp',x))\n",
    "df['Participant'] = df['Text'].apply(lambda x: extract_timestamp('Participant',x))\n",
    "df['Message'] = df['Text'].apply(lambda x: extract_timestamp('Message',x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Exclusion of invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding group name\n",
    "try:\n",
    "    grp_name = re.search('“([^“”]+)”',df.loc[0,'Message']).group(1)\n",
    "\n",
    "    #Excluding rows with Participant as group name\n",
    "    exceptions_df = df[df['Participant']==grp_name].reset_index(drop=True)\n",
    "    exceptions_df['Flag'] = 'Rows automatically created by WhatsApp'\n",
    "\n",
    "    df = df[df['Participant']!=grp_name].reset_index(drop=True)\n",
    "except:\n",
    "    exceptions_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding rows with Participant as WhatsApp\n",
    "exc = df[df['Participant'].str.contains('WhatsApp')]\n",
    "exc['Flag'] = 'Invalid rows'\n",
    "exceptions_df = pd.concat([exceptions_df,exc],ignore_index=True)\n",
    "\n",
    "df = df[~df['Participant'].str.contains('WhatsApp')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding invalid rows based on Timestamp length. These are due to forwarded messages\n",
    "df['Len'] = df['Timestamp'].apply(lambda x: len(x.split(',')[0]))\n",
    "\n",
    "exc = df[df['Len']==5]\n",
    "exc['Flag'] = 'Forwarded messages'\n",
    "exceptions_df = pd.concat([exceptions_df,exc],ignore_index=True)\n",
    "\n",
    "df = df[df['Len']!=5].reset_index(drop=True)\n",
    "\n",
    "#Dropping temporary len column\n",
    "df.drop(columns='Len',inplace=True)\n",
    "exceptions_df.drop(columns='Len',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Final cleaning of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing whitespace from timestamp column\n",
    "df['Timestamp'] = df['Timestamp'].str.strip()\n",
    "\n",
    "#Creating date and time columns from timestamp\n",
    "df.loc[:,['Date','Time']] = df['Timestamp'].str.split(',',expand=True).rename(columns={0:'Date',1:'Time'})\n",
    "\n",
    "#Rearranging columns and dropping timestamp\n",
    "df = df[['Text','Participant','Date','Time','Message']]\n",
    "\n",
    "#Reassigning blank values in Participant, Date and Time columns as None\n",
    "df.loc[df['Date']=='',['Participant','Date','Time']] = None\n",
    "\n",
    "#Forwarding filling none columns\n",
    "df.loc[:,['Participant','Date','Time']] = df.loc[:,['Participant','Date','Time']].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date and time columns into pandas date/time, and then a timestamp column\n",
    "df['Date'] = pd.to_datetime(df['Date'].str.strip(),format='%d/%m/%Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'].str.strip(), format='%H:%M:%S').dt.time\n",
    "df['Timestamp'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Transforming dataframe to concatenate messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating messages after grouping by timestamp and participant\n",
    "final_df = df.groupby(['Timestamp','Participant'])['Message'].agg(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating date descriptors from timestamp column\n",
    "final_df['Date'] = final_df['Timestamp'].dt.date\n",
    "final_df['Month-year'] = final_df['Timestamp'].dt.strftime(\"%B %Y\")\n",
    "final_df['Day of Week'] = final_df['Timestamp'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating VADER sentiment analysis classification\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Creating function to get sentiment scores\n",
    "def get_sentiment_score(sentence):\n",
    "    score = analyzer.polarity_scores(sentence)['compound']\n",
    "    if score<-0.05:\n",
    "        return 'Negative'\n",
    "    elif score>0.05:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "#Applying sentiment analysis classification to the Message column\n",
    "final_df['Sentiment'] = final_df['Message'].apply(get_sentiment_score)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generating a Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating all text into a single string\n",
    "text = ' '.join(final_df['Message'])\n",
    "\n",
    "#Generating the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white',max_words=30).generate(text)\n",
    "\n",
    "#Plotting the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
